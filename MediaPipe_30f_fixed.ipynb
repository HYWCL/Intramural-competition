{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "order_number = '12'\n",
    "   \n",
    "npy_save_path = r'H:\\1.media_pipe\\수어 영상\\npy' \\\n",
    "                + '\\\\' + order_number + '_real_word_npy_30f_F_U_D_fixed'\n",
    "os.makedirs(npy_save_path, exist_ok=True)\n",
    "error_path = r'H:\\1.media_pipe\\수어 영상\\npy\\error'\n",
    "error_txt = open(error_path + '\\\\' + npy_save_path.split('\\\\')[-1] + '.txt', 'a')\n",
    "video_path = r'H:\\1.media_pipe\\수어 영상\\1.Training' \\\n",
    "            + '\\\\' + order_number\n",
    "Label = pd.read_csv(r'H:\\1.media_pipe\\수어 영상\\Label' \\\n",
    "                    + '\\\\' + order_number + '_real_word_label.csv')\n",
    "\n",
    "video_list = os.listdir(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## origin video_list_len :  15000\n",
      "## new_video_list_len :  489\n",
      "## video[0] :  NIA_SL_WORD0009_REAL12_D.mp4\n",
      "## save npy folder :  12_real_word_npy_30f_F_U_D_fixed\n",
      "\n",
      "## label data\n",
      "                           name  duration  start    end label\n",
      "0  NIA_SL_WORD0001_REAL12_D.mp4       4.7   1.88  3.717    고민\n",
      "1  NIA_SL_WORD0001_REAL12_F.mp4       4.7   1.88  3.717    고민\n",
      "2  NIA_SL_WORD0001_REAL12_L.mp4       4.7   1.88  3.717    고민\n",
      "3  NIA_SL_WORD0001_REAL12_R.mp4       4.7   1.88  3.717    고민\n",
      "4  NIA_SL_WORD0001_REAL12_U.mp4       4.7   1.88  3.717    고민\n"
     ]
    }
   ],
   "source": [
    "l_F = Label[Label['name'].str.contains('_F.mp4')]\n",
    "l_U = Label[Label['name'].str.contains('_U.mp4')]\n",
    "l_D = Label[Label['name'].str.contains('_D.mp4')]\n",
    "\n",
    "l_F = l_F.append(l_U)\n",
    "l_F = l_F.append(l_D)\n",
    "l_F.head()\n",
    "\n",
    "label_cl_4 = pd.read_csv('./Label_classification_4.csv', encoding='CP949')\n",
    "\n",
    "label_cl_4_list = []\n",
    "label_cl_4_list.append(label_cl_4['동사'].dropna().to_list())\n",
    "label_cl_4_list.append(label_cl_4['명사'].dropna().to_list())\n",
    "label_cl_4_list.append(label_cl_4['형용사'].dropna().to_list())\n",
    "\n",
    "label_cl_4_list = sum(label_cl_4_list, [])\n",
    "len(label_cl_4_list)\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "for a in label_cl_4_list:\n",
    "    tmp = l_F[l_F['label'] == a]\n",
    "    new_df = new_df.append(tmp)\n",
    "\n",
    "\n",
    "new_video_list = new_df['name'].sort_values().to_list()\n",
    "len(new_video_list)\n",
    "\n",
    "print('## origin video_list_len : ', len(video_list))\n",
    "print('## new_video_list_len : ', len(new_video_list))\n",
    "print('## video[0] : ', new_video_list[0])\n",
    "print('## save npy folder : ', npy_save_path.split('\\\\')[-1])\n",
    "print('\\n## label data')\n",
    "print(Label.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/489 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 31/489 [01:40<24:22,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find hand on 4 frames\n",
      "NIA_SL_WORD0694_REAL12_D.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 34/489 [01:49<24:13,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIA_SL_WORD0702_REAL12_D.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 35/489 [01:52<23:46,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIA_SL_WORD0702_REAL12_F.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 36/489 [01:55<23:28,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIA_SL_WORD0702_REAL12_U.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 64/489 [03:10<20:37,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIA_SL_WORD1000_REAL12_D.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 65/489 [03:13<19:17,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIA_SL_WORD1000_REAL12_F.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 66/489 [03:15<18:17,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIA_SL_WORD1000_REAL12_U.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 67/489 [03:17<16:18,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find hand on 4 frames\n",
      "NIA_SL_WORD1096_REAL12_D.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 85/489 [04:04<12:56,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find hand on 4 frames\n",
      "NIA_SL_WORD1139_REAL12_D.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 115/489 [05:18<10:30,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find hand on 4 frames\n",
      "NIA_SL_WORD1171_REAL12_D.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 136/489 [06:09<11:45,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find hand on 4 frames\n",
      "NIA_SL_WORD1204_REAL12_D.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 271/489 [12:04<10:06,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIA_SL_WORD1390_REAL12_D.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 272/489 [12:07<10:19,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIA_SL_WORD1390_REAL12_F.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 273/489 [12:10<10:16,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIA_SL_WORD1390_REAL12_U.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 373/489 [16:40<05:48,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIA_SL_WORD2132_REAL12_D.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 374/489 [16:43<05:46,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIA_SL_WORD2132_REAL12_F.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 375/489 [16:46<05:37,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIA_SL_WORD2132_REAL12_U.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [21:44<00:00,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Error Count :  17\n",
      "## Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "error_count = 0\n",
    "\n",
    "for k, j in enumerate(tqdm(new_video_list)):\n",
    "\n",
    "    # if k == 1: # test\n",
    "    #     break\n",
    "    # j = 'NIA_SL_WORD1384_REAL04_F.mp4' #test\n",
    "\n",
    "    cap = cv2.VideoCapture(os.path.join(video_path, j))\n",
    "\n",
    "    right_keypoints = []\n",
    "    left_keypoints = []\n",
    "    both_hands_list = []\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    # start = int(Label.iloc[k]['start'] * 30)\n",
    "    # end = int(Label.iloc[k]['end'] * 30)\n",
    "    \n",
    "    # duration = int(Label.iloc[k]['duration'] * 30)\n",
    "    duration = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    \n",
    "    \n",
    "    duration_division = duration // 30\n",
    "    \n",
    "    duration_division_list = [duration_division * i for i in range(31)]\n",
    "\n",
    "    # print('## duration : ', duration)\n",
    "    # print('## duration_d : ', duration_division)\n",
    "    \n",
    "    with mp_hands.Hands(\n",
    "        model_complexity = 0,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as hands:\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(image)\n",
    "            \n",
    "            right_keypoint = np.zeros((21, 3))\n",
    "            left_keypoint = np.zeros((21, 3))\n",
    "\n",
    "            if results.multi_hand_landmarks is not None and frame_count != 0:\n",
    "                if len(results.multi_hand_landmarks) == 2:\n",
    "                    for i in range(21):\n",
    "                        if results.multi_hand_landmarks[0].landmark[0].x > results.multi_hand_landmarks[1].landmark[0].x:\n",
    "                            right_keypoint[i, 0] = results.multi_hand_landmarks[0].landmark[i].x\n",
    "                            right_keypoint[i, 1] = results.multi_hand_landmarks[0].landmark[i].y\n",
    "                            right_keypoint[i, 2] = results.multi_hand_landmarks[0].landmark[i].z\n",
    "\n",
    "                            left_keypoint[i, 0] = results.multi_hand_landmarks[1].landmark[i].x\n",
    "                            left_keypoint[i, 1] = results.multi_hand_landmarks[1].landmark[i].y\n",
    "                            left_keypoint[i, 2] = results.multi_hand_landmarks[1].landmark[i].z\n",
    "                        else:\n",
    "                            right_keypoint[i, 0] = results.multi_hand_landmarks[1].landmark[i].x\n",
    "                            right_keypoint[i, 1] = results.multi_hand_landmarks[1].landmark[i].y\n",
    "                            right_keypoint[i, 2] = results.multi_hand_landmarks[1].landmark[i].z\n",
    "\n",
    "                            left_keypoint[i, 0] = results.multi_hand_landmarks[0].landmark[i].x\n",
    "                            left_keypoint[i, 1] = results.multi_hand_landmarks[0].landmark[i].y\n",
    "                            left_keypoint[i, 2] = results.multi_hand_landmarks[0].landmark[i].z\n",
    "\n",
    "\n",
    "                right_keypoints.append(right_keypoint)\n",
    "                left_keypoints.append(left_keypoint)\n",
    "            \n",
    "\n",
    "            if frame_count in duration_division_list and frame_count != 0:\n",
    "                # print('frame_count', frame_count)\n",
    "                \n",
    "                # print('# ', np.sum(right_keypoints, axis=1))\n",
    "                right_keypoints = np.array(right_keypoints)\n",
    "                left_keypoints = np.array(left_keypoints)\n",
    "\n",
    "                # print(str(right_keypoints.shape))\n",
    "                # print()\n",
    "                try:\n",
    "                    r_zero_count = sum(np.sum(right_keypoints, axis=1)[:, 0] == 0)\n",
    "                    l_zero_count = sum(np.sum(left_keypoints, axis=1)[:, 0] == 0)\n",
    "                except:\n",
    "                    print('cannot find hand on 4 frames')\n",
    "                    break\n",
    "\n",
    "                right_sum = np.sum(right_keypoints, axis=0)\n",
    "                left_sum = np.sum(left_keypoints, axis=0)\n",
    "\n",
    "                right_mean = right_sum / (duration_division - r_zero_count)\n",
    "                left_mean = left_sum / (duration_division - l_zero_count)\n",
    "\n",
    "                # right_mean = np.mean(right_keypoints, axis=0)\n",
    "                # # right_std = np.std(right_keypoints, axis=0)\n",
    "                # left_mean = np.mean(left_keypoints, axis=0)\n",
    "                # left_std = np.std(left_keypoints, axis=0)\n",
    "                # both_hands = np.concatenate((right_mean, left_mean, right_std, left_std))\n",
    "                \n",
    "                # both_hands = np.concatenate((right_mean, left_mean))\n",
    "                \n",
    "                try:\n",
    "                    both_hands = np.concatenate((right_mean, left_mean))\n",
    "                    # both_hands = np.concatenate((right_mean, left_mean, right_std, left_std))\n",
    "                except:\n",
    "                    print('both_error')\n",
    "                    break\n",
    "                \n",
    "                both_hands_list.append(both_hands)\n",
    "\n",
    "                right_keypoints = []\n",
    "                left_keypoints = []\n",
    "                \n",
    "            frame_count += 1\n",
    "        \n",
    "        try:\n",
    "            save_file = np.array(both_hands_list)\n",
    "            save_file = save_file.reshape(3780)\n",
    "            np.save(npy_save_path + f'\\\\{j[:-4]}.npy', save_file)\n",
    "        except:\n",
    "            print(j)\n",
    "            error_txt.write(j + '\\n')\n",
    "            error_count += 1\n",
    "            continue\n",
    "\n",
    "cap.release()\n",
    "error_txt.close()\n",
    "print()\n",
    "print('## Error Count : ', error_count)\n",
    "print('## Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 추출 중 문제점 기록\n",
    "1. 4프레임 동안 손을 찾지 못하여 right_hands 의 shape이 (0,) 이 되는 문제\n",
    "2. 4프레임 중 양 손을 찾지 못해 스킵된 채 진행되어 (duration_division, 21, 3)의 사이즈가 아닌 데이터가 존재\n",
    " 2번 예시 정상 데이터 == (4, 21, 3) / 오류 데이터 == (3, 21, 3) or (2, 21, 3)이 존재\n",
    "3. nan.....\n",
    "3-1. nan 원인 : 0을 0으로 나누는 상황으로 추측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
