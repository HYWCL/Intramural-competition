{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-08T03:00:50.520684Z","iopub.status.busy":"2023-10-08T03:00:50.520314Z","iopub.status.idle":"2023-10-08T03:00:50.527121Z","shell.execute_reply":"2023-10-08T03:00:50.525748Z","shell.execute_reply.started":"2023-10-08T03:00:50.520658Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.notebook import tqdm\n","from sklearn.preprocessing import LabelEncoder\n","\n","import numpy as np\n","import pandas as pd\n","\n","import random\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T03:01:06.622226Z","iopub.status.busy":"2023-10-08T03:01:06.621862Z","iopub.status.idle":"2023-10-08T03:01:06.648562Z","shell.execute_reply":"2023-10-08T03:01:06.647761Z","shell.execute_reply.started":"2023-10-08T03:01:06.622200Z"},"trusted":true},"outputs":[],"source":["# Label_Path = '/kaggle/input/signdata/cat_data_npy_word/Label_v2.csv'\n","# Label = pd.read_csv(Label_Path)\n","\n","# Label = Label.sample(frac=1).reset_index(drop=True)\n","\n","# Train_Label = Label[:2400]\n","# Val_Label = Label[2400:]\n","\n","# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# print(Train_Label.head().to_markdown())\n","# print(Val_Label.head().to_markdown())"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T03:01:08.693272Z","iopub.status.busy":"2023-10-08T03:01:08.692922Z","iopub.status.idle":"2023-10-08T03:01:08.699112Z","shell.execute_reply":"2023-10-08T03:01:08.697354Z","shell.execute_reply.started":"2023-10-08T03:01:08.693245Z"},"trusted":true},"outputs":[],"source":["## Sign Language Label Encoding\n","\n","finger_incoder = {'안녕하세요' : 0, '감사합니다' : 1, '맞다' : 2, '아니다' : 3,\n","                     '좋다' : 4, '싫다' : 5, '있다' : 6, '없다' : 7, '괜찮다' : 8,\n","                     '아프다' : 9, '잘하다' : 10, '못하다' : 11, '나' : 12, '너' : 13,\n","                     '가족' : 14, '수어' : 15, '약속' : 16, '이름' : 17, \n","                     '머리' : 18, '목' : 19, '가렵다' : 20}\n","\n","finger_decoder = {0 : '안녕하세요', 1 : '감사합니다', 2 : '맞다', 3  : \"아니다\",\n","                     4 : '좋다', 5 : '싫다', 6 : '있다', 7 : '없다', 8 : '괜찮다',\n","                     9 : '아프다', 10 : '잘하다', 11 : '못하다', 12 : '나', 13 : '너',\n","                     14 : '가족', 15 : '수어', 16 : '약속', 17 : '이름',\n","                     18 : '머리', 19 : '목', 20 : '가렵다'}"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T03:03:03.745913Z","iopub.status.busy":"2023-10-08T03:03:03.745570Z","iopub.status.idle":"2023-10-08T03:03:03.761767Z","shell.execute_reply":"2023-10-08T03:03:03.760742Z","shell.execute_reply.started":"2023-10-08T03:03:03.745886Z"},"trusted":true},"outputs":[],"source":["## Train, Validation DataSet Calss\n","\n","# class Train_SignDataSet(Dataset):\n","#     def __init__(self, df_label):\n","#         super().__init__()\n","\n","#         self.df_label = df_label\n","\n","#     def __len__(self):\n","#         return len(self.df_label)\n","    \n","#     def __getitem__(self, idx):\n","#         data = np.load(self.df_label.iloc[idx]['path'])\n","#         data = self.DataTransform(data)\n","#         data = self.DataNormalization(data)\n","#         data = torch.tensor(data).type(torch.float32)\n","\n","#         label = self.df_label.iloc[idx]['label']\n","#         label = finger_incoder[label]\n","\n","#         return data, label\n","    \n","#     def DataNormalization(self, data):\n","#         data = data.reshape(30, 42, 3)\n","\n","#         left_x = data[:, :21, 0]\n","#         right_x = data[:, 21:42, 0]\n","#         left_y = data[:, :21, 1]\n","#         right_y = data[:, 21:42, 1]\n","#         left_z = data[:, :21, 2]\n","#         right_z = data[:, 21:42, 2]\n","\n","#         data[:, :21, 0] -= np.min(left_x)\n","#         data[:, :21, 0] /= (np.max(left_x) - np.min(left_x))\n","#         data[:, 21:42, 0] -= np.min(right_x)\n","#         data[:, 21:42, 0] /= (np.max(right_x) - np.min(right_x))\n","\n","#         data[:, :21, 1] -= np.min(left_y)\n","#         data[:, :21, 1] /= (np.max(left_y) - np.min(left_y))\n","#         data[:, 21:42, 1] -= np.min(right_y)\n","#         data[:, 21:42, 1] /= (np.max(right_y) - np.min(right_y))\n","\n","#         data[:, :21, 2] -= np.min(left_z)\n","#         data[:, :21, 2] /= (np.max(left_z) - np.min(left_z))\n","#         data[:, 21:42, 2] -= np.min(right_z)\n","#         data[:, 21:42, 2] /= (np.max(right_z) - np.min(right_z))\n","        \n","#         data = data.reshape(3780)\n","        \n","#         return data\n","    \n","#     def DataTransform(self, data):\n","#         x_points_random = np.random.uniform(-0.01, 0.01)\n","#         y_points_random = np.random.uniform(-0.01, 0.01)\n","\n","#         data = data.reshape(30, 42, 3)\n","\n","#         data[:, :21, 0] += x_points_random\n","#         data[:, 21:42, 0] += x_points_random\n","#         data[:, :21, 1] += y_points_random\n","#         data[:, 21:42, 1] += y_points_random\n","#         data = data.reshape(3780)\n","\n","#         return data\n","    \n","# class Val_SignDataSet(Dataset):\n","#     def __init__(self, df_label):\n","#         super().__init__()\n","        \n","#         self.df_label = df_label\n","        \n","#     def __len__(self):\n","#         return len(self.df_label)\n","    \n","#     def __getitem__(self, idx):\n","#         data = np.load(self.df_label.iloc[idx]['path'])\n","#         data = self.DataNormalization(data)\n","#         data = torch.tensor(data).type(torch.float32)\n","        \n","#         label = self.df_label.iloc[idx]['label']\n","#         label = finger_incoder[label]\n","        \n","#         return data, label\n","    \n","#     def DataNormalization(self, data):\n","#         data = data.reshape(30, 42, 3)\n","\n","#         left_x = data[:, :21, 0]\n","#         right_x = data[:, 21:42, 0]\n","#         left_y = data[:, :21, 1]\n","#         right_y = data[:, 21:42, 1]\n","#         left_z = data[:, :21, 2]\n","#         right_z = data[:, 21:42, 2]\n","\n","#         data[:, :21, 0] -= np.min(left_x)\n","#         data[:, :21, 0] /= (np.max(left_x) - np.min(left_x))\n","#         data[:, 21:42, 0] -= np.min(right_x)\n","#         data[:, 21:42, 0] /= (np.max(right_x) - np.min(right_x))\n","\n","#         data[:, :21, 1] -= np.min(left_y)\n","#         data[:, :21, 1] /= (np.max(left_y) - np.min(left_y))\n","#         data[:, 21:42, 1] -= np.min(right_y)\n","#         data[:, 21:42, 1] /= (np.max(right_y) - np.min(right_y))\n","\n","#         data[:, :21, 2] -= np.min(left_z)\n","#         data[:, :21, 2] /= (np.max(left_z) - np.min(left_z))\n","#         data[:, 21:42, 2] -= np.min(right_z)\n","#         data[:, 21:42, 2] /= (np.max(right_z) - np.min(right_z))\n","        \n","#         data = data.reshape(3780)\n","        \n","#         return data"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["## DataSet Class for WebCam Data\n","\n","class Cam_SignDataSet(Dataset):\n","    def __init__(self, df_label):\n","        super().__init__()\n","        \n","        self.df_label = df_label\n","        \n","    def __len__(self):\n","        return len(self.df_label)\n","    \n","    def __getitem__(self, idx):\n","        data = self.df_label\n","        data = self.DataNormalization(data)\n","        data = torch.tensor(data).type(torch.float32)\n","        \n","        return data\n","    \n","    def DataNormalization(self, data):\n","        data = data.reshape(30, 42, 3)\n","\n","        left_x = data[:, :21, 0]\n","        right_x = data[:, 21:42, 0]\n","        left_y = data[:, :21, 1]\n","        right_y = data[:, 21:42, 1]\n","        left_z = data[:, :21, 2]\n","        right_z = data[:, 21:42, 2]\n","\n","        data[:, :21, 0] -= np.min(left_x)\n","        data[:, :21, 0] /= (np.max(left_x) - np.min(left_x))\n","        data[:, 21:42, 0] -= np.min(right_x)\n","        data[:, 21:42, 0] /= (np.max(right_x) - np.min(right_x))\n","\n","        data[:, :21, 1] -= np.min(left_y)\n","        data[:, :21, 1] /= (np.max(left_y) - np.min(left_y))\n","        data[:, 21:42, 1] -= np.min(right_y)\n","        data[:, 21:42, 1] /= (np.max(right_y) - np.min(right_y))\n","\n","        data[:, :21, 2] -= np.min(left_z)\n","        data[:, :21, 2] /= (np.max(left_z) - np.min(left_z))\n","        data[:, 21:42, 2] -= np.min(right_z)\n","        data[:, 21:42, 2] /= (np.max(right_z) - np.min(right_z))\n","        \n","        data = data.reshape(3780)\n","        \n","        return data"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T03:03:05.689678Z","iopub.status.busy":"2023-10-08T03:03:05.689336Z","iopub.status.idle":"2023-10-08T03:03:05.695737Z","shell.execute_reply":"2023-10-08T03:03:05.694112Z","shell.execute_reply.started":"2023-10-08T03:03:05.689649Z"},"trusted":true},"outputs":[],"source":["# train_ds = Train_SignDataSet(Train_Label)\n","# val_ds = Val_SignDataSet(Val_Label)\n","\n","# train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, pin_memory=True)\n","# val_dl = DataLoader(val_ds, batch_size=32, shuffle=False, pin_memory=True)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T03:03:06.999014Z","iopub.status.busy":"2023-10-08T03:03:06.998577Z","iopub.status.idle":"2023-10-08T03:03:07.010419Z","shell.execute_reply":"2023-10-08T03:03:07.008853Z","shell.execute_reply.started":"2023-10-08T03:03:06.998987Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([3780])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# train_ds[0][0].shape"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T03:03:09.284919Z","iopub.status.busy":"2023-10-08T03:03:09.284563Z","iopub.status.idle":"2023-10-08T03:03:09.291447Z","shell.execute_reply":"2023-10-08T03:03:09.289811Z","shell.execute_reply.started":"2023-10-08T03:03:09.284894Z"},"trusted":true},"outputs":[],"source":["def save_model(name, model):\n","    torch.save(model.state_dict(), f'{name}.pth')\n","    \n","def load_model(model, name, path='.'):\n","    data = torch.load(os.path.join(path, f'{name}.pth'), map_location='cpu')\n","    model.load_state_dict(data)\n","    return model"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T03:03:32.443618Z","iopub.status.busy":"2023-10-08T03:03:32.443287Z","iopub.status.idle":"2023-10-08T03:03:32.449383Z","shell.execute_reply":"2023-10-08T03:03:32.448143Z","shell.execute_reply.started":"2023-10-08T03:03:32.443573Z"},"trusted":true},"outputs":[],"source":["class ASLModel(nn.Module):\n","    def __init__(self):\n","        super(ASLModel, self).__init__()\n","        self.layer0 = nn.Linear(3780, 1890)\n","        self.layer1 = nn.Linear(1890, 945)\n","        self.layer2 = nn.Linear(945, 21)\n","        \n","    def forward(self, x):\n","        x = self.layer0(x)\n","        x = F.relu(x)\n","        x = self.layer1(x)\n","        x = F.relu(x)\n","        x = self.layer2(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T03:03:35.139958Z","iopub.status.busy":"2023-10-08T03:03:35.139619Z","iopub.status.idle":"2023-10-08T03:05:09.375466Z","shell.execute_reply":"2023-10-08T03:05:09.374342Z","shell.execute_reply.started":"2023-10-08T03:03:35.139932Z"},"trusted":true},"outputs":[],"source":["## Model Train\n","\n","# import time\n","\n","# def train_model(train_dl, train_loss_list, val_loss_list, val_acc_list, time_list, epochs):\n","#     train_total = len(train_dl.dataset)\n","#     val_total = len(val_dl.dataset)\n","#     save_loss = 10\n","    \n","#     model = ASLModel()\n","#     model = model.to(DEVICE)\n","    \n","#     loss_fun = nn.CrossEntropyLoss()\n","#     optim = torch.optim.Adam(model.parameters(), lr=0.00001)\n","#     scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr=0.0005, epochs=epochs, steps_per_epoch=len(train_dl))\n","    \n","#     for epoch in tqdm(range(epochs), desc='Epoch'):\n","#         start = time.time()\n","#         model.train()\n","#         train_loss = 0\n","#         train_correct = 0\n","        \n","#         val_loss = 0\n","#         val_correct = 0\n","        \n","#         with tqdm(train_dl, desc='Train') as train_progress:\n","#             for batch_idx, (X, y) in enumerate(train_progress):\n","#                 model.train()\n","#                 optim.zero_grad()\n","#                 y = y.to(DEVICE)\n","# #                 print(y)\n","                \n","#                 y_pred = model(X.to(DEVICE))\n","#                 y_loss = loss_fun(y_pred, y)\n","                \n","#                 train_loss += y_loss.item() * y.size(0)\n","                \n","#                 y_loss.backward()\n","#                 optim.step()\n","#                 scheduler.step()\n","                \n","#                 predict = torch.argmax(y_pred, dim=-1)\n","#                 train_correct += y.eq(predict).sum()\n","                \n","#             train_acc = train_correct / train_total\n","#             train_loss = train_loss / train_total\n","            \n","#             train_loss_list.append(train_loss)\n","            \n","#             print('epoch: {} --> train_loss: {:.4f} - train_acc: {:.4f} - '.format(epoch, train_loss, train_acc), end='')\n","            \n","#         with tqdm(val_dl, desc='Val') as val_progress:\n","#             for batch_idx, (X, y) in enumerate(val_progress):\n","#                 model.eval()\n","#                 y = y.to(DEVICE)\n","                \n","#                 y_pred = model(X.to(DEVICE))\n","#                 y_loss = loss_fun(y_pred, y)\n","                \n","#                 val_loss += y_loss.item() * y.size(0)\n","#                 predict = torch.argmax(y_pred, dim=-1)\n","#                 val_correct += y.eq(predict).sum()\n","                \n","#             val_acc = val_correct / val_total\n","#             val_loss = val_loss / val_total\n","            \n","#             val_loss_list.append(val_loss)\n","#             val_acc_list.append(val_acc.item())\n","            \n","#             if val_loss < save_loss:\n","#                 save_loss = val_loss\n","#                 save_model('Save_Model', model)\n","#                 print(\"Save_Model!\")\n","            \n","#             print('epoch: {} --> val_loss: {:.4f} - val_acc: {:.4f}'.format(epoch, val_loss, val_acc))\n","            \n","#         end = time.time()\n","#         elapsed_time = end - start\n","#         time_list.append(elapsed_time)\n","    \n","# train_loss_list = []\n","# val_loss_list = []\n","# val_acc_list = []\n","# time_list = []\n","\n","# train_model(train_dl, train_loss_list, val_loss_list, val_acc_list, time_list, 10)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1024.0 576.0\n"]}],"source":["## Real Time WebCam Data Operation & UI\n","\n","import cv2\n","import time\n","from PIL import ImageFont, ImageDraw, Image\n","import mediapipe as mp\n","mp_drawing = mp.solutions.drawing_utils\n","mp_drawing_styles = mp.solutions.drawing_styles\n","mp_hands = mp.solutions.hands\n","\n","new_model = load_model(ASLModel(), 'Save_Model')\n","\n","count = 0\n","\n","t_result = '0'\n","right_keypoints = []\n","left_keypoints = []\n","both_hands_list = []\n","t_pred_list = []\n","result_keypoint = []\n","result_word_lst = []\n","text = ''\n","starting_delay_count = 0\n","\n","cap = cv2.VideoCapture(cv2.CAP_DSHOW + 0)\n","cap.set(cv2.CAP_PROP_FRAME_WIDTH, 960)\n","cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 540)\n","a1 = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n","a2 = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n","\n","print(a1, a2)\n","# cap.set(cv2.CAP_PROP_FPS, 30)\n","frame_rate = 30\n","prev = 0\n","result_str = ''\n","back_img1 = np.zeros((100, 1024, 3))\n","back_img1[:] = 255\n","        \n","cap_fps = cap.get(cv2.CAP_PROP_FPS)\n","cap_fps_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","cap_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n","cap_pos_frames = cap.get(cv2.CAP_PROP_POS_FRAMES)\n","\n","with mp_hands.Hands(\n","    model_complexity=0,\n","    min_detection_confidence=0.5,\n","    min_tracking_confidence=0.5) as hands:\n","    while cap.isOpened():\n","        success, image = cap.read()\n","        if not success:\n","            print(\"카메라를 찾을 수 없습니다.\")\n","            break\n","        \n","        image.flags.writeable = False\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        results = hands.process(image)\n","        \n","        right_keypoint = np.zeros((21, 3))\n","        left_keypoint = np.zeros((21, 3))\n","        \n","        try:\n","            if len(results.multi_hand_landmarks) == 2:\n","                for i in range(21):\n","                    if results.multi_hand_landmarks[0].landmark[0].x > results.multi_hand_landmarks[1].landmark[0].x:\n","                        right_keypoint[i, 0] = results.multi_hand_landmarks[0].landmark[i].x\n","                        right_keypoint[i, 1] = results.multi_hand_landmarks[0].landmark[i].y\n","                        right_keypoint[i, 2] = results.multi_hand_landmarks[0].landmark[i].z\n","\n","                        left_keypoint[i, 0] = results.multi_hand_landmarks[1].landmark[i].x\n","                        left_keypoint[i, 1] = results.multi_hand_landmarks[1].landmark[i].y\n","                        left_keypoint[i, 2] = results.multi_hand_landmarks[1].landmark[i].z\n","                    else:\n","                        right_keypoint[i, 0] = results.multi_hand_landmarks[1].landmark[i].x\n","                        right_keypoint[i, 1] = results.multi_hand_landmarks[1].landmark[i].y\n","                        right_keypoint[i, 2] = results.multi_hand_landmarks[1].landmark[i].z\n","\n","                        left_keypoint[i, 0] = results.multi_hand_landmarks[0].landmark[i].x\n","                        left_keypoint[i, 1] = results.multi_hand_landmarks[0].landmark[i].y\n","                        left_keypoint[i, 2] = results.multi_hand_landmarks[0].landmark[i].z\n","                both_hand = np.concatenate((right_keypoint, left_keypoint))\n","        except:\n","            pass\n","        \n","        \n","        count += 1\n","        \n","        if count > 29 and results.multi_hand_landmarks is not None:\n","            try:\n","                result_keypoint = []\n","                for i in range(30):\n","                    result_keypoint.append(both_hand)\n","                save_file = np.array(result_keypoint)\n","                save_file = save_file.reshape(3780)\n","                save_file = pd.DataFrame(save_file)\n","                save_file = save_file.fillna(0)\n","                save_file = save_file.replace(0, np.NaN)\n","                save_file = save_file.fillna(method='ffill')\n","                save_file = save_file.to_numpy()\n","                s_data = Cam_SignDataSet(save_file)\n","                t_pred = new_model(s_data[0])\n","                t_predict = torch.argmax(t_pred, dim=-1)\n","                t_pred_list.append(t_predict.item())\n","                t_result = t_predict\n","                result_str = str(finger_decoder[int(t_result)])\n","                result_word_lst.append(result_str)\n","                result_keypoint = []\n","                count = 0\n","            except:\n","                result_keypoint = []\n","                count = 0\n","                continue\n","\n","        # 이미지에 손 주석을 그립니다.\n","        image.flags.writeable = True\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        if results.multi_hand_landmarks:\n","            for hand_landmarks in results.multi_hand_landmarks:\n","                mp_drawing.draw_landmarks(\n","                    image,\n","                    hand_landmarks,\n","                    mp_hands.HAND_CONNECTIONS,\n","                    mp_drawing_styles.DrawingSpec(\n","                        color = (0,255,0),\n","                        thickness = 1,\n","                        circle_radius = 3),\n","                    mp_drawing_styles.DrawingSpec(\n","                        color = (255, 255, 255),\n","                        thickness = 2,\n","                        circle_radius = 1))\n","        \n","        if starting_delay_count < 30:\n","            result_word_lst = ['프로그램 시작 대기']\n","            starting_delay_count += 1\n","        elif starting_delay_count == 30:\n","            result_word_lst = ['준비 완료 / 시작']\n","            starting_delay_count += 1\n","        \n","        if cv2.waitKey(1) & 0xFF == ord('d'):\n","            result_word_lst = []\n","                \n","        image = cv2.flip(image, 1)\n","        \n","        org = (5, 20)\n","        font = ImageFont.truetype(\"fonts/gulim.ttc\", 30)\n","        box_color = (255, 255, 255)\n","        font_scale = 2\n","        thinkness = 3\n","        \n","        back_img1 = np.zeros((100, 1024, 3))\n","        back_img1[:] = 255\n","        \n","        count_str = str(int(count))\n","        \n","        if len(text) > 40:\n","            del result_word_lst[0]\n","        \n","        words_sum = \"\"\n","        for i in result_word_lst:\n","            words_sum += i + \", \"\n","        \n","        text = \" 수어단어 :: \" +  words_sum\n","        \n","        back_img1 = Image.fromarray(back_img1.astype(np.uint8))\n","        draw = ImageDraw.Draw(back_img1) \n","        draw.text(org, text, font=font, fill=(0,0,0))\n","        \n","        back_img1 = np.array(back_img1)\n","        \n","        image = Image.fromarray(image.astype(np.uint8))\n","        count_font = ImageFont.truetype(\"fonts/gulim.ttc\", 40)\n","        draw_count = ImageDraw.Draw(image)\n","        draw_count.text((5, 5), count_str, fill=(0, 255, 0), font=count_font)\n","        image = np.array(image)\n","        \n","        aa = np.concatenate((image, back_img1), axis=0)\n","        \n","        aa = np.array(aa, dtype=np.uint8)\n","        \n","        cv2.imshow('MediaPipe Hands', aa)\n","    \n","        if cv2.waitKey(5) & 0xFF == 27:\n","            break\n","\n","cap.release()\n","cv2.destroyAllWindows()"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"6a926afa313b26ae1264fdcf81c726a97e69f6ba2ba780f6aa901948710f8d6e"}}},"nbformat":4,"nbformat_minor":4}
