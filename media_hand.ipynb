{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import natsort\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## video folder first name NIA_SL_WORD0001_REAL16_D.mp4 \n",
      "\n",
      "## origin video list len :  15000\n",
      "## new_video_list_len :  3\n",
      "## save video npy folder :  16_real_word_npy_all_frame_video\n",
      "## save img npy folder :  16_real_word_npy_all_frame_img\n",
      "\n",
      "## new label data\n",
      "                              name  duration  start    end label\n",
      "4735  NIA_SL_WORD0948_REAL16_D.mp4     3.834  1.359  2.554   가깝다\n",
      "4736  NIA_SL_WORD0948_REAL16_F.mp4     3.834  1.359  2.554   가깝다\n",
      "4739  NIA_SL_WORD0948_REAL16_U.mp4     3.834  1.359  2.554   가깝다\n"
     ]
    }
   ],
   "source": [
    "order_number = '01'\n",
    "   \n",
    "npy_video_save_path = r'C:\\Users\\user\\Documents\\0_2024_signLang_simul\\npy_video' \\\n",
    "                + '\\\\' + order_number + '_real_word_npy_all_frame_video'\n",
    "npy_img_save_path = r'C:\\Users\\user\\Documents\\0_2024_signLang_simul\\npy_img' \\\n",
    "                + '\\\\' + order_number + '_real_word_npy_all_frame_img'\n",
    "\n",
    "os.makedirs(npy_video_save_path, exist_ok=True)\n",
    "os.makedirs(npy_img_save_path, exist_ok=True)\n",
    "\n",
    "error_path = r'C:\\Users\\user\\Documents\\0_2024_signLang_simul\\npy_error'\n",
    "\n",
    "# error_txt = open(error_path + '\\\\' + npy_video_save_path.split('\\\\')[-1] + '.txt', 'a')\n",
    "# error_txt = open(error_path + '\\\\' + npy_img_save_path.split('\\\\')[-1] + '.txt', 'a')\n",
    "\n",
    "video_path = r'C:\\Users\\user\\Documents\\0_signlang_download\\수어 영상\\1.Training' \\\n",
    "            + '\\\\' + order_number\n",
    "            \n",
    "img_tmp_path = r'C:\\Users\\user\\Documents\\0_signlang_download\\img_tmp'\n",
    "\n",
    "Label = pd.read_csv(r'C:\\Users\\user\\Documents\\0_2024_signLang_simul\\labels' \\\n",
    "                    + '\\\\' + order_number + '_real_word_label.csv')\n",
    "\n",
    "video_list = os.listdir(video_path)\n",
    "print('## video folder first name', video_list[0], '\\n')\n",
    "\n",
    "one_word = '가깝다'\n",
    "video_d = ['_F.np4', '_U.mp4', '_D.mp4']\n",
    "\n",
    "new_video_list = Label[Label['label'] == one_word]\n",
    "new_video_list = new_video_list[new_video_list['name'].str.contains('_F.mp4') | \n",
    "                                new_video_list['name'].str.contains('_U.mp4') | \\\n",
    "                                new_video_list['name'].str.contains('_D.mp4')]\n",
    "\n",
    "print('## origin video list len : ', len(video_list))\n",
    "print('## new_video_list_len : ', len(new_video_list))\n",
    "print('## save video npy folder : ', npy_video_save_path.split('\\\\')[-1])\n",
    "print('## save img npy folder : ', npy_img_save_path.split('\\\\')[-1])\n",
    "print('\\n## new label data')\n",
    "print(new_video_list.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:52<00:00, 17.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Process No. 16\n",
      "## Error Count :  0\n",
      "## Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "error_count = 0\n",
    "\n",
    "for k, j in enumerate(tqdm(new_video_list['name'])):\n",
    "    # if k == 1:\n",
    "    #     break\n",
    "    # cap = cv2.VideoCapture('./sample/videos/가깝다.mp4')\n",
    "    cap = cv2.VideoCapture(os.path.join(video_path, j))\n",
    "\n",
    "    right_keypoints = []\n",
    "    left_keypoints = []\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    duration = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    # print('## duration is ', duration)\n",
    "\n",
    "    both_hands = np.zeros((int(duration), 42, 3))\n",
    "\n",
    "    with mp_hands.Hands(\n",
    "        model_complexity = 0,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as hands:\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "            \n",
    "            cap_img_save_path = os.path.join(img_tmp_path, str(frame_count) + '.png')\n",
    "            cv2.imwrite(cap_img_save_path, image)\n",
    "            \n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(image)\n",
    "            \n",
    "            right_keypoint = np.zeros((21, 3))\n",
    "            left_keypoint = np.zeros((21, 3))\n",
    "\n",
    "            if results.multi_hand_landmarks is not None:\n",
    "                if len(results.multi_hand_landmarks) == 2:\n",
    "                    for i in range(21):\n",
    "                        if results.multi_hand_landmarks[0].landmark[0].x > results.multi_hand_landmarks[1].landmark[0].x:\n",
    "                            right_keypoint[i, 0] = results.multi_hand_landmarks[0].landmark[i].x\n",
    "                            right_keypoint[i, 1] = results.multi_hand_landmarks[0].landmark[i].y\n",
    "                            right_keypoint[i, 2] = results.multi_hand_landmarks[0].landmark[i].z\n",
    "\n",
    "                            left_keypoint[i, 0] = results.multi_hand_landmarks[1].landmark[i].x\n",
    "                            left_keypoint[i, 1] = results.multi_hand_landmarks[1].landmark[i].y\n",
    "                            left_keypoint[i, 2] = results.multi_hand_landmarks[1].landmark[i].z\n",
    "                        else:\n",
    "                            right_keypoint[i, 0] = results.multi_hand_landmarks[1].landmark[i].x\n",
    "                            right_keypoint[i, 1] = results.multi_hand_landmarks[1].landmark[i].y\n",
    "                            right_keypoint[i, 2] = results.multi_hand_landmarks[1].landmark[i].z\n",
    "\n",
    "                            left_keypoint[i, 0] = results.multi_hand_landmarks[0].landmark[i].x\n",
    "                            left_keypoint[i, 1] = results.multi_hand_landmarks[0].landmark[i].y\n",
    "                            left_keypoint[i, 2] = results.multi_hand_landmarks[0].landmark[i].z\n",
    "            \n",
    "            left_keypoint = np.array(left_keypoint)\n",
    "            right_keypoint = np.array(right_keypoint)\n",
    "            both_hand = np.concatenate((left_keypoint, right_keypoint), axis=0)\n",
    "            # print(both_hand.shape)\n",
    "            # print(both_hand)\n",
    "            both_hands[frame_count] = both_hand\n",
    "            \n",
    "            frame_count += 1\n",
    "        \n",
    "        try:\n",
    "            save_file = np.array(both_hands)\n",
    "            # print('## both_hands shape is', both_hands.shape)\n",
    "            save_file = save_file.flatten()\n",
    "            np.save(npy_video_save_path + f'\\\\{j[:-4]}.npy', save_file)\n",
    "        except:\n",
    "            print(j)\n",
    "            error_count += 1\n",
    "            \n",
    "            \n",
    "    ## image to mediapipe\n",
    "    png_lst = os.listdir(img_tmp_path)\n",
    "\n",
    "    IMAGE_FILES = [img_tmp_path + '//' + x for x in png_lst]\n",
    "    IMAGE_FILES = natsort.natsorted(png_lst)\n",
    "\n",
    "    # print(IMAGE_FILES[0])\n",
    "\n",
    "    right_keypoints = []\n",
    "    left_keypoints = []\n",
    "    both_hands = np.zeros((len(png_lst), 42, 3))\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    with mp_hands.Hands(\n",
    "        static_image_mode=True,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5) as hands:\n",
    "        for idx, file in enumerate(IMAGE_FILES):\n",
    "            # a_image = cv2.flip(cv2.imread(file), 1)\n",
    "            a_image = cv2.imread(img_tmp_path + '/' + file)\n",
    "            \n",
    "            image = a_image.copy()\n",
    "            \n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(image)\n",
    "            \n",
    "            if not results.multi_hand_landmarks:\n",
    "                continue\n",
    "            \n",
    "            right_keypoint = np.zeros((21, 3))\n",
    "            left_keypoint = np.zeros((21, 3))\n",
    "\n",
    "            if results.multi_hand_landmarks is not None:\n",
    "                if len(results.multi_hand_landmarks) == 2:\n",
    "                    for i in range(21):\n",
    "                        if results.multi_hand_landmarks[0].landmark[0].x > results.multi_hand_landmarks[1].landmark[0].x:\n",
    "                            right_keypoint[i, 0] = results.multi_hand_landmarks[0].landmark[i].x\n",
    "                            right_keypoint[i, 1] = results.multi_hand_landmarks[0].landmark[i].y\n",
    "                            right_keypoint[i, 2] = results.multi_hand_landmarks[0].landmark[i].z\n",
    "\n",
    "                            left_keypoint[i, 0] = results.multi_hand_landmarks[1].landmark[i].x\n",
    "                            left_keypoint[i, 1] = results.multi_hand_landmarks[1].landmark[i].y\n",
    "                            left_keypoint[i, 2] = results.multi_hand_landmarks[1].landmark[i].z\n",
    "                        else:\n",
    "                            right_keypoint[i, 0] = results.multi_hand_landmarks[1].landmark[i].x\n",
    "                            right_keypoint[i, 1] = results.multi_hand_landmarks[1].landmark[i].y\n",
    "                            right_keypoint[i, 2] = results.multi_hand_landmarks[1].landmark[i].z\n",
    "\n",
    "                            left_keypoint[i, 0] = results.multi_hand_landmarks[0].landmark[i].x\n",
    "                            left_keypoint[i, 1] = results.multi_hand_landmarks[0].landmark[i].y\n",
    "                            left_keypoint[i, 2] = results.multi_hand_landmarks[0].landmark[i].z\n",
    "            \n",
    "            left_keypoint = np.array(left_keypoint)\n",
    "            right_keypoint = np.array(right_keypoint)\n",
    "            both_hand = np.concatenate((left_keypoint, right_keypoint), axis=0)\n",
    "            # print(both_hand.shape)\n",
    "            # print(both_hand)\n",
    "            both_hands[idx] = both_hand\n",
    "            \n",
    "            frame_count += 1\n",
    "        \n",
    "        try:\n",
    "            save_file = np.array(both_hands)\n",
    "            # print('## both_hands shape is', both_hands.shape)\n",
    "            save_file = save_file.flatten()\n",
    "            np.save(npy_img_save_path + f'\\\\{j[:-4]}.npy', save_file)\n",
    "        except:\n",
    "            print(j)\n",
    "            error_count += 1\n",
    "    shutil.rmtree(img_tmp_path)\n",
    "    os.makedirs(img_tmp_path, exist_ok=True)\n",
    "        \n",
    "    \n",
    "cap.release()\n",
    "print()\n",
    "print('## Process No.', order_number)\n",
    "print('## Error Count : ', error_count)\n",
    "print('## Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a926afa313b26ae1264fdcf81c726a97e69f6ba2ba780f6aa901948710f8d6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
